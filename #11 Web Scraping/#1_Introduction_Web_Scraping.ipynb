{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Introduction to Web Scraping\n",
    "\n",
    "Web scraping is a technique to automatically access and extract large amounts of information from a website, which can save a huge amount of time and effort. In this guide, we’ll be touring the essential stack of Python web scraping libraries. We’ll show you the tricks to get the job done with just a few lines of code."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f09756854dfc48f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The Main things we need to understand:\n",
    "\n",
    "- Rule of web scraping\n",
    "- Limitation of web scraping\n",
    "- Basic HTML and CSS"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "862c6a855c0a3651"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Rule of web scraping\n",
    "\n",
    "- Always check a website’s Terms and Conditions before you scrape it. Be careful to read the statements about legal use of data. Usually, the data you scrape should not be used for commercial purposes.\n",
    "\n",
    "- If you make too many requests too quickly, the target website might block you. To be on the safe side, make one request per second.\n",
    "\n",
    "- Some sites automatically block IP addresses that send too many requests. By rotating your IP addresses, you can make the scraper requests look like they are coming from different computers.\n",
    "\n",
    "### The limitation of web scraping\n",
    "\n",
    "- In general, web scraping is legal as long as you use it in an ethical way and don’t violate the website’s Terms of Service. Instead of copying and pasting data from a website, you can use an API to fetch data from a web server. With APIs, you can avoid parsing HTML and instead access the data directly using formats like JSON and XML.\n",
    "\n",
    "- A slight change or update to the website may completely break your scraper. In this case, you have to rewrite your CSS locator.\n",
    "\n",
    "### Basic HTML and CSS\n",
    "\n",
    "- HTML is the standard markup language for creating web pages and web applications. With Cascading Style Sheets (CSS), we can define how HTML elements are displayed. HTML and CSS are the fundamental technologies for building web pages.\n",
    "\n",
    "- CSS is a language that describes the style of an HTML document. CSS describes how HTML elements should be displayed. This tutorial will teach you CSS from basic to advanced.\n",
    "\n",
    "- JavaScript is the programming language of HTML and the Web programming language that adds interactivity to your website. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "94e3627b43672e60"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The main libraries for web scraping in Python\n",
    "\n",
    "- Requests: Requests is a simple and elegant Python HTTP library. It provides methods for accessing Web resources via HTTP."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8633215d850db5e8"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (2.31.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests) (2019.11.28)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests) (1.25.8)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests) (2.8)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T19:37:07.501158665Z",
     "start_time": "2024-01-05T19:37:03.005228387Z"
    }
   },
   "id": "221e56cc518791f6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- lxml: lxml is a Python library which allows for easy handling of XML and HTML files, and can also be used for web scraping. It is a very fast and extensible tool, and apart from parsing XML, it can also be used for creating and modifying XML and HTML files."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "41fa05eea16aa0e1"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in /usr/lib/python3/dist-packages (4.5.0)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lxml"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T19:37:10.797122553Z",
     "start_time": "2024-01-05T19:37:07.507590149Z"
    }
   },
   "id": "6dcaf5adc16139c1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- beautifulsoup4: Beautiful Soup is a Python library for pulling data out of HTML and XML files. It works with your favorite parser to provide idiomatic ways of navigating, searching, and modifying the parse tree."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa1c3e0cc082d472"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\r\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\r\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/lib/python3/dist-packages (from bs4) (4.8.2)\r\n",
      "Building wheels for collected packages: bs4\r\n",
      "  Building wheel for bs4 (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1272 sha256=944681bd1cd789e6c99eb3a658b8f19f01909b93eacd49c30fd9b61506b3d567\r\n",
      "  Stored in directory: /home/nidhood/.cache/pip/wheels/75/78/21/68b124549c9bdc94f822c02fb9aa3578a669843f9767776bca\r\n",
      "Successfully built bs4\r\n",
      "Installing collected packages: bs4\r\n",
      "Successfully installed bs4-0.0.1\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install bs4"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T19:37:19.028053981Z",
     "start_time": "2024-01-05T19:37:14.051891198Z"
    }
   },
   "id": "cd252c0bdf17449b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88a68ca70d49a2cc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
